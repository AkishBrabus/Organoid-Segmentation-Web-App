{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "from EmbedSeg.utils.preprocess_data import extract_data, split_train_val, get_data_properties\n",
    "from EmbedSeg.utils.generate_crops import *\n",
    "from EmbedSeg.utils.visualize import visualize_many_crops\n",
    "import json\n",
    "from matplotlib.colors import ListedColormap"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T21:38:22.607498300Z",
     "start_time": "2024-05-02T21:38:20.496846Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T21:39:00.974141100Z",
     "start_time": "2024-05-02T21:39:00.942893100Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\cryst\\Desktop\\Organoid-Segmentation-Web-App\\training'\n",
    "project_name = 'Colon Organoid 5_2_2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, <b>*.tif</b>-type images and the corresponding masks should be respectively present under <b>images</b> and <b>masks</b>, under directories <b>train</b>, <b>val</b> and <b>test</b>, which can be present at any location on your workstation, pointed to by the variable <i>data_dir</i>. (In order to prepare such instance masks, one could use the Fiji plugin <b>Labkit</b> as detailed <a href= \"https://github.com/juglab/EmbedSeg/wiki/01---Use-Labkit-to-prepare-instance-masks\"> here</a>). The following would be the desired structure as to how data should be present. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/juglab/EmbedSeg/v0.2.4/directory_pngs/png/01_dir_structure.png\" width=\"100\"/>\n",
    "\n",
    "If you already have your data available in the above style, please skip to the <b><a href=\"#center\">third</a></b> section of this notebook, where you specify the kind of center to which constitutive pixels of an object should embed. \n",
    "Since for the <b> dsb-2018</b> dataset, we do not have the data in this format yet, we firstly download the data from an external url in the following cells, next we split this data to create our `train`, `val` and `test` directories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images and corresponding masks are downloaded from an external url, specified by `zip_url` to the path specified by the variables `data_dir` and `project_name`. The following structure is generated after executing the `extract_data` and `split_train_val` methods below:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/juglab/EmbedSeg/v0.2.4/directory_pngs/png/03_dsb-2018.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "ExecuteTime": {
     "end_time": "2023-11-08T04:51:31.915908400Z",
     "start_time": "2023-11-08T04:51:29.032240700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded data as C:\\Users\\cryst\\Desktop\\EmbedSeg Organoid\\data_dir\\OrganoID_Dataset_1172023.zip\n",
      "Unzipped data to C:\\Users\\cryst\\Desktop\\EmbedSeg Organoid\\data_dir\\OrganoID_Dataset_1172023\\download/\n"
     ]
    }
   ],
   "source": [
    "extract_data(\n",
    "    zip_url = 'https://github.com/juglab/EmbedSeg/releases/download/v0.1.0/dsb-2018.zip',\n",
    "    data_dir = data_dir,\n",
    "    project_name = project_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into `train`, `val` \\& `test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we would like to reserve a small fraction (15 % by default) of the provided train dataset as validation data. Here, in case you would like to repeat multiple experiments with the same partition, you may continue and press <kbd>Shift</kbd> + <kbd>Enter</kbd> on the next cell - but in case, you would like different partitions each time, please add the `seed` attribute equal to a different integer (For example, \n",
    "```\n",
    "split_train_val(\n",
    "data_dir = data_dir, \n",
    "project_name = project_name, \n",
    "train_val_name = 'train', \n",
    "subset = 0.15, \n",
    "seed = 1000)\n",
    "```\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Val-Test Images/Masks copied to ../../../data/dsb-2018\n"
     ]
    }
   ],
   "source": [
    "split_train_val(\n",
    "    data_dir = data_dir,\n",
    "    project_name = project_name, \n",
    "    train_val_name = 'train',\n",
    "    subset = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify desired centre location for spatial embedding of pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior pixels of an object instance can either be embedded at the `medoid`, the `approximate-medoid` or the `centroid`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T21:39:10.056804Z",
     "start_time": "2024-05-02T21:39:10.041179900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Embedding Location chosen as : medoid\n"
     ]
    }
   ],
   "source": [
    "center = 'medoid' # 'medoid', 'approximate-medoid', 'centroid'\n",
    "try:\n",
    "    assert center in {'medoid', 'approximate-medoid', 'centroid'}\n",
    "    print(\"Spatial Embedding Location chosen as : {}\".format(center))\n",
    "except AssertionError as e:\n",
    "    e.args += ('Please specify center as one of : {\"medoid\", \"approximate-medoid\", \"centroid\"}', 42)\n",
    "    raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate some dataset specific properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we will calculate properties of the data such as `min_object_size`, `foreground_weight` etc. <br>\n",
    "We will also specify some properties, for example,  \n",
    "* set `one_hot = True` in case the instances are encoded in a one-hot style. \n",
    "* set `data_properties_dir['data_type']='16-bit'` if the images are of datatype `unsigned 16 bit` and \n",
    "    `data_properties_dir['data_type']='8-bit'` if the images are of datatype `unsigned 8 bit`.\n",
    "\n",
    "Lastly, we will save the dictionary `data_properties_dir` in a json file, which we will access in the `02-train` and `03-predict` notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T21:54:26.384876400Z",
     "start_time": "2024-05-02T21:54:22.891518300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 217.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreground weight of the `Colon Organoid 5_2_2024` dataset set equal to 10.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:03<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum object size of the `Colon Organoid 5_2_2024` dataset is equal to 2\n",
      "Mean object size of the `Colon Organoid 5_2_2024` dataset is equal to 5278.885462555066\n",
      "Maximum object size of the `Colon Organoid 5_2_2024` dataset is equal to 62125\n",
      "Average object size of the `Colon Organoid 5_2_2024` dataset along `x` = 70.784\n",
      "Std. dev object size of the `Colon Organoid 5_2_2024` dataset along `x` = 48.056\n",
      "Average object size of the `Colon Organoid 5_2_2024` dataset along `y` = 69.172\n",
      "Std. dev object size of the `Colon Organoid 5_2_2024` dataset along `y` = 48.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 127.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile size of the `Colon Organoid 5_2_2024` dataset set equal to (1392, 1392)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 136.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average background intensity of the `Colon Organoid 5_2_2024` dataset set                     equal to 307.879\n",
      "Dataset properties of the `Colon Organoid 5_2_2024` dataset is saved to `data_properties.json`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "one_hot = False\n",
    "data_properties_dir = get_data_properties(data_dir, project_name, train_val_name=['train', 'val'], \n",
    "                                          test_name=['test'], mode='2d', one_hot=one_hot, process_k=None)\n",
    "\n",
    "data_properties_dir['data_type']='8-bit'\n",
    "\n",
    "with open(os.path.join(data_dir, project_name, 'data_properties.json'), 'w') as outfile:\n",
    "    json.dump(data_properties_dir, outfile)\n",
    "    print(\"Dataset properties of the `{}` dataset is saved to `data_properties.json`\".format(project_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify cropping configuration parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images and the corresponding masks are cropped into patches centred around an object instance, which are pre-saved prior to initiating the training. Note that the cropped images, masks and center-images would be saved at the path specified by `crops_dir` (The parameter `crops_dir` is set to ```./crops``` by default, which creates a directory at the same location as this notebook). Here, `data_subset` defines the directory which is processed. \n",
    "\n",
    "Note that we automatically calculate  the `crop_size` by using the `avg_object_size` and `std_object_size` through the relation:\n",
    "$\\text{crop_size_i} = \\text{avg_obj_size_i} + \\text{n_sigma} \\times \\text{std_obj_size_i}$ where $i \\in \\{x,y\\}$ and `n_sigma` equals `5` by default.\n",
    "\n",
    "Please feel free to reduce the parameter `n_sigma` to be equal to `3-4` in case of lower GPU memory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T21:39:27.236280900Z",
     "start_time": "2024-05-02T21:39:27.220653900Z"
    }
   },
   "outputs": [],
   "source": [
    "n_sigma = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T21:39:28.683180600Z",
     "start_time": "2024-05-02T21:39:28.667553100Z"
    }
   },
   "outputs": [],
   "source": [
    "def round_up_8(x):\n",
    "    return (x.astype(int)+7) & (-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-02T21:44:09.192457700Z",
     "start_time": "2024-05-02T21:44:09.176832100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop size in x and y will be set equal to 264\n"
     ]
    }
   ],
   "source": [
    "crops_dir = os.path.join(data_dir, project_name, \"crops\")\n",
    "data_subsets = ['train', 'val'] \n",
    "crop_size = np.maximum(round_up_8(data_properties_dir['avg_object_size_y'] + n_sigma*data_properties_dir['stdev_object_size_y']),\n",
    "round_up_8(data_properties_dir['avg_object_size_x'] + n_sigma*data_properties_dir['stdev_object_size_x']))\n",
    "print(\"Crop size in x and y will be set equal to {}\".format(crop_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Crops\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    The cropped images and masks are saved at the same-location as the example notebooks. <br>\n",
    "    Generating the crops would take a little while!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While cropping images, we normalize them by following any one of three strategies: \n",
    "\n",
    "(i) `min-max-percentile` (default) \n",
    "(ii) `mean-std` \n",
    "(iii) `absolute` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T21:44:14.080917200Z",
     "start_time": "2024-05-02T21:44:14.065289200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization chosen as : min-max-percentile\n"
     ]
    }
   ],
   "source": [
    "norm = 'min-max-percentile'\n",
    "try:\n",
    "    assert norm in {'min-max-percentile', 'mean-std', 'absolute'}\n",
    "    print(\"Normalization chosen as : {}\".format(norm))\n",
    "except AssertionError as e:\n",
    "    e.args += ('Please specify norm as one of : {\"min-max-percentile\", \"mean-std\", \"absolute\"}', 42)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T21:54:22.875892500Z",
     "start_time": "2024-05-02T21:44:14.718837600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory : C:\\Users\\cryst\\Desktop\\Organoid-Segmentation-Web-App\\training\\Colon Organoid 5_2_2024\\crops\\Colon Organoid 5_2_2024\\train\\images/\n",
      "Created new directory : C:\\Users\\cryst\\Desktop\\Organoid-Segmentation-Web-App\\training\\Colon Organoid 5_2_2024\\crops\\Colon Organoid 5_2_2024\\train\\masks/\n",
      "Created new directory : C:\\Users\\cryst\\Desktop\\Organoid-Segmentation-Web-App\\training\\Colon Organoid 5_2_2024\\crops\\Colon Organoid 5_2_2024\\train\\center-medoid/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [07:29<00:00, 29.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping of images, instances and centre_images for data_subset = `train` done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory : C:\\Users\\cryst\\Desktop\\Organoid-Segmentation-Web-App\\training\\Colon Organoid 5_2_2024\\crops\\Colon Organoid 5_2_2024\\val\\images/\n",
      "Created new directory : C:\\Users\\cryst\\Desktop\\Organoid-Segmentation-Web-App\\training\\Colon Organoid 5_2_2024\\crops\\Colon Organoid 5_2_2024\\val\\masks/\n",
      "Created new directory : C:\\Users\\cryst\\Desktop\\Organoid-Segmentation-Web-App\\training\\Colon Organoid 5_2_2024\\crops\\Colon Organoid 5_2_2024\\val\\center-medoid/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:38<00:00, 79.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropping of images, instances and centre_images for data_subset = `val` done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from EmbedSeg.utils.generate_crops import *\n",
    "\n",
    "for data_subset in data_subsets:\n",
    "    image_dir = os.path.join(data_dir, project_name, data_subset, 'images')\n",
    "    instance_dir = os.path.join(data_dir, project_name, data_subset, 'masks')\n",
    "    image_names = sorted(glob(os.path.join(image_dir, '*.tif'))) \n",
    "    instance_names = sorted(glob(os.path.join(instance_dir, '*.tif')))  \n",
    "    for i in tqdm(np.arange(len(image_names))):\n",
    "        if one_hot:\n",
    "            process_one_hot(image_names[i], instance_names[i], os.path.join(crops_dir, project_name), data_subset, crop_size, center, one_hot = one_hot, norm=norm, data_type = data_properties_dir['data_type'])\n",
    "        else:\n",
    "            process(image_names[i], instance_names[i], os.path.join(crops_dir, project_name), data_subset, crop_size, center, one_hot=one_hot, norm=norm, data_type = data_properties_dir['data_type'])\n",
    "    print(\"Cropping of images, instances and centre_images for data_subset = `{}` done!\".format(data_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `norm` in `normalization.json` file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-05-02T21:54:22.891518300Z",
     "start_time": "2024-05-02T21:54:22.875892500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization properties of the `Colon Organoid 5_2_2024` dataset is saved to `normalization.json`\n"
     ]
    }
   ],
   "source": [
    "normalization = {}\n",
    "normalization['data_type']=data_properties_dir['data_type']\n",
    "normalization['norm']=norm\n",
    "with open(os.path.join(data_dir, project_name, 'normalization.json'), 'w') as outfile:\n",
    "    json.dump(normalization, outfile)\n",
    "    print(\"Normalization properties of the `{}` dataset is saved to `normalization.json`\".format(project_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize cropped images, corresponding ground truth masks and object center images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T05:40:19.321695400Z",
     "start_time": "2023-11-08T05:40:19.274805100Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../cmaps/cmap_60.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m new_cmap \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../../../cmaps/cmap_60.npy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m new_cmap \u001B[38;5;241m=\u001B[39m ListedColormap(new_cmap) \u001B[38;5;66;03m# new_cmap = 'magma' would also work! \u001B[39;00m\n\u001B[0;32m      3\u001B[0m visualize_many_crops(data_dir\u001B[38;5;241m=\u001B[39mcrops_dir, project_name\u001B[38;5;241m=\u001B[39mproject_name, train_val_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m, center\u001B[38;5;241m=\u001B[39mcenter, n_images\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, new_cmp\u001B[38;5;241m=\u001B[39mnew_cmap, one_hot\u001B[38;5;241m=\u001B[39mone_hot)\n",
      "File \u001B[1;32m~\\Desktop\\EmbedSeg Organoid\\venv\\lib\\site-packages\\numpy\\lib\\npyio.py:390\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001B[0m\n\u001B[0;32m    388\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    389\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 390\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    391\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../../cmaps/cmap_60.npy'"
     ]
    }
   ],
   "source": [
    "new_cmap = np.load('../../../cmaps/cmap_60.npy')\n",
    "new_cmap = ListedColormap(new_cmap) # new_cmap = 'magma' would also work! \n",
    "visualize_many_crops(data_dir=crops_dir, project_name=project_name, train_val_dir='val', center=center, n_images=5, new_cmp=new_cmap, one_hot=one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
